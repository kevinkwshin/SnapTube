import streamlit as st
import google.generativeai as genai
import requests
import re
from urllib.parse import urlparse, parse_qs
import xml.etree.ElementTree as ET
import html
import json

def extract_video_id(url):
    """YouTube URLì—ì„œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ"""
    if not url:
        return None
    url = url.strip()
    
    if "youtube.com/watch" in url:
        try:
            parsed_url = urlparse(url)
            return parse_qs(parsed_url.query)['v'][0]
        except (KeyError, IndexError):
            return None
    elif "youtu.be/" in url:
        try:
            return url.split("youtu.be/")[1].split("?")[0]
        except IndexError:
            return None
    elif "youtube.com/embed/" in url:
        try:
            return url.split("embed/")[1].split("?")[0]
        except IndexError:
            return None
    elif re.fullmatch(r"^[a-zA-Z0-9_-]{11}$", url):
        return url
    else:
        return None

def get_transcript(video_id):
    """ìë§‰ ê°€ì ¸ì˜¤ê¸° - ì—¬ëŸ¬ ë°©ë²• ì‹œë„"""
    
    progress_placeholder = st.empty()
    
    # ë°©ë²• 1: í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ (ê°€ì¥ ì•ˆì •ì )
    try:
        progress_placeholder.info("ğŸ”„ ë°©ë²• 1: í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ì‹œë„ ì¤‘...")
        url = f"https://www.youtube.com/watch?v={video_id}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'
        }
        
        response = requests.get(url, headers=headers, timeout=20)
        
        if response.status_code == 200:
            page_content = response.text
            
            # ì—¬ëŸ¬ íŒ¨í„´ìœ¼ë¡œ ì‹œë„
            patterns = [
                r'"captionTracks":\s*(\[.*?\])',
                r'"captions".*?"captionTracks":\s*(\[.*?\])',
                r'captionTracks["\']:\s*(\[.*?\])'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, page_content, re.DOTALL)
                if match:
                    try:
                        tracks_str = match.group(1)
                        # ìœ ë‹ˆì½”ë“œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                        tracks_str = tracks_str.encode('utf-8').decode('unicode_escape')
                        tracks = json.loads(tracks_str)
                        
                        if tracks:
                            progress_placeholder.success(f"âœ… {len(tracks)}ê°œ ìë§‰ íŠ¸ë™ ë°œê²¬")
                            
                            # ìˆ˜ë™ ìƒì„± ìë§‰ ìš°ì„ 
                            manual_tracks = [t for t in tracks if t.get('kind') != 'asr' and 'baseUrl' in t]
                            auto_tracks = [t for t in tracks if t.get('kind') == 'asr' and 'baseUrl' in t]
                            
                            selected_track = None
                            track_type = None
                            
                            if manual_tracks:
                                selected_track = manual_tracks[0]
                                track_type = "ìˆ˜ë™"
                            elif auto_tracks:
                                selected_track = auto_tracks[0]
                                track_type = "ìë™"
                            
                            if selected_track and 'baseUrl' in selected_track:
                                caption_url = selected_track['baseUrl']
                                lang = selected_track.get('languageCode', 'unknown')
                                
                                # ìë§‰ ë‚´ìš© ë‹¤ìš´ë¡œë“œ
                                caption_response = requests.get(caption_url, headers=headers, timeout=15)
                                
                                if caption_response.status_code == 200:
                                    return parse_caption_xml(caption_response.text, f"{track_type} ìƒì„± ({lang})", progress_placeholder)
                                    
                    except (json.JSONDecodeError, KeyError):
                        continue
    
    except Exception as e:
        progress_placeholder.warning(f"ë°©ë²• 1 ì‹¤íŒ¨: {str(e)[:50]}...")
    
    # ë°©ë²• 2: timedtext API
    try:
        progress_placeholder.info("ğŸ”„ ë°©ë²• 2: timedtext API ì‹œë„ ì¤‘...")
        list_url = f"https://www.youtube.com/api/timedtext?type=list&v={video_id}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(list_url, headers=headers, timeout=15)
        
        if response.status_code == 200 and response.text.strip():
            try:
                root = ET.fromstring(response.text)
                tracks = root.findall('.//track')
                
                if tracks:
                    progress_placeholder.success(f"âœ… {len(tracks)}ê°œ ìë§‰ íŠ¸ë™ ë°œê²¬")
                    
                    # ìˆ˜ë™ ìƒì„± ìš°ì„ 
                    manual_tracks = [t for t in tracks if t.get('kind') != 'asr']
                    auto_tracks = [t for t in tracks if t.get('kind') == 'asr']
                    
                    selected_track = None
                    track_type = None
                    
                    if manual_tracks:
                        selected_track = manual_tracks[0]
                        track_type = "ìˆ˜ë™"
                    elif auto_tracks:
                        selected_track = auto_tracks[0]
                        track_type = "ìë™"
                    
                    if selected_track:
                        lang_code = selected_track.get('lang_code', 'unknown')
                        caption_url = f"https://www.youtube.com/api/timedtext?lang={lang_code}&v={video_id}"
                        
                        if selected_track.get('kind') == 'asr':
                            caption_url += "&kind=asr"
                        
                        caption_response = requests.get(caption_url, headers=headers, timeout=15)
                        
                        if caption_response.status_code == 200:
                            return parse_caption_xml(caption_response.text, f"{track_type} ìƒì„± ({lang_code})", progress_placeholder)
                            
            except ET.ParseError as e:
                progress_placeholder.warning(f"XML íŒŒì‹± ì‹¤íŒ¨: {str(e)[:50]}...")
                
    except Exception as e:
        progress_placeholder.warning(f"ë°©ë²• 2 ì‹¤íŒ¨: {str(e)[:50]}...")
    
    # ë°©ë²• 3: ë‹¤ë¥¸ User-Agentë¡œ ì¬ì‹œë„
    try:
        progress_placeholder.info("ğŸ”„ ë°©ë²• 3: ë‹¤ë¥¸ ë¸Œë¼ìš°ì €ë¡œ ì¬ì‹œë„ ì¤‘...")
        url = f"https://www.youtube.com/watch?v={video_id}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=20)
        
        if response.status_code == 200:
            match = re.search(r'"captionTracks":\s*(\[.*?\])', response.text)
            
            if match:
                try:
                    tracks_str = match.group(1).encode('utf-8').decode('unicode_escape')
                    tracks = json.loads(tracks_str)
                    
                    if tracks:
                        for track in tracks:
                            if 'baseUrl' in track:
                                caption_url = track['baseUrl']
                                lang = track.get('languageCode', 'unknown')
                                track_type = "ìˆ˜ë™" if track.get('kind') != 'asr' else "ìë™"
                                
                                caption_response = requests.get(caption_url, headers=headers, timeout=15)
                                
                                if caption_response.status_code == 200:
                                    result = parse_caption_xml(caption_response.text, f"{track_type} ìƒì„± ({lang})", progress_placeholder)
                                    if result[0]:  # ì„±ê³µí•˜ë©´ ë°”ë¡œ ë°˜í™˜
                                        return result
                                        
                except (json.JSONDecodeError, KeyError):
                    pass
                    
    except Exception as e:
        progress_placeholder.warning(f"ë°©ë²• 3 ì‹¤íŒ¨: {str(e)[:50]}...")
    
    progress_placeholder.empty()
    return None, None

def parse_caption_xml(xml_content, method_info, progress_placeholder):
    """XML ìë§‰ íŒŒì‹±"""
    try:
        root = ET.fromstring(xml_content)
        texts = []
        
        # ë‹¤ì–‘í•œ íƒœê·¸ ì‹œë„
        for tag in ['text', 'p', 's']:
            elements = root.findall(f'.//{tag}')
            if elements:
                for elem in elements:
                    if elem.text and elem.text.strip():
                        clean_text = html.unescape(elem.text.strip())
                        clean_text = re.sub(r'\n+', ' ', clean_text)
                        texts.append(clean_text)
                break
        
        if texts:
            full_text = ' '.join(texts)
            full_text = re.sub(r'\s+', ' ', full_text).strip()
            
            if len(full_text) > 30:
                progress_placeholder.success(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ! ({method_info})")
                return full_text, method_info
        
        # XML íŒŒì‹± ì‹¤íŒ¨ì‹œ ì •ê·œì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
        text_matches = re.findall(r'<text[^>]*>(.*?)</text>', xml_content, re.DOTALL)
        if text_matches:
            texts = []
            for match in text_matches:
                clean_text = re.sub(r'<[^>]+>', '', match)
                clean_text = html.unescape(clean_text.strip())
                if clean_text:
                    texts.append(clean_text)
            
            if texts:
                full_text = ' '.join(texts)
                full_text = re.sub(r'\s+', ' ', full_text).strip()
                
                if len(full_text) > 30:
                    progress_placeholder.success(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ! ({method_info})")
                    return full_text, method_info
        
    except ET.ParseError:
        # ì™„ì „íˆ ë‹¤ë¥¸ í˜•ì‹ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì •ê·œì‹ìœ¼ë¡œ ì‹œë„
        text_content = re.sub(r'<[^>]+>', '', xml_content)
        text_content = html.unescape(text_content).strip()
        if len(text_content) > 30:
            progress_placeholder.success(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ! ({method_info})")
            return text_content, method_info
    
    return None, None

def summarize_text(text, api_key):
    """Geminië¡œ ìš”ì•½ ìƒì„±"""
    try:
        genai.configure(api_key=api_key)
        
        if len(text) > 30000:
            text = text[:30000]
            st.caption("ìë§‰ì´ ë„ˆë¬´ ê¸¸ì–´ ì•ë¶€ë¶„ë§Œ ìš”ì•½ì— ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        model = genai.GenerativeModel('gemini-1.5-flash-latest')
        
        prompt = f"""ë‹¤ìŒ YouTube ìë§‰ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

ìë§‰ ë‚´ìš©:
{text}

ìš”ì•½ í˜•ì‹:
## ğŸ“Œ ì£¼ìš” ì£¼ì œ
## ğŸ”‘ í•µì‹¬ ë‚´ìš© (3-5ê°œ)
## ğŸ’¡ ê²°ë¡  ë° ì‹œì‚¬ì 

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""
        
        response = model.generate_content(prompt)
        return response.text
        
    except Exception as e:
        return f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}"

def main():
    st.set_page_config(
        page_title="YouTube ìë§‰ ìš”ì•½ê¸°",
        page_icon="ğŸ“º",
        layout="wide"
    )
    
    st.title("ğŸ“º YouTube ìë§‰ ìš”ì•½ê¸°")
    st.markdown("YouTube ë¹„ë””ì˜¤ì˜ ìë§‰ì„ ì¶”ì¶œí•˜ê³  Gemini AIë¡œ ìš”ì•½í•©ë‹ˆë‹¤.")
    
    gemini_api_key = st.text_input(
        "ğŸ”‘ Gemini API Key",
        type="password",
        help="Google AI Studioì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤"
    )
    
    video_input = st.text_input(
        "ğŸ¥ YouTube URL ë˜ëŠ” ë¹„ë””ì˜¤ ID",
        placeholder="ì˜ˆ: https://www.youtube.com/watch?v=dQw4w9WgXcQ"
    )
    
    if st.button("ğŸš€ ìë§‰ ì¶”ì¶œ ë° ìš”ì•½", type="primary", disabled=(not gemini_api_key)):
        if not video_input:
            st.error("YouTube URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        
        video_id = extract_video_id(video_input)
        if not video_id:
            st.error("ìœ íš¨í•œ YouTube URLì´ ì•„ë‹™ë‹ˆë‹¤.")
            return
        
        st.info(f"ğŸ¯ ë¹„ë””ì˜¤ ID: {video_id}")
        
        # ìë§‰ ì¶”ì¶œ
        with st.spinner("ìë§‰ ì¶”ì¶œ ì¤‘..."):
            transcript_text, method = get_transcript(video_id)
        
        if not transcript_text:
            st.error("âŒ ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # ë””ë²„ê¹…ì„ ìœ„í•´ ì§ì ‘ í…ŒìŠ¤íŠ¸í•´ë³´ê¸°
            st.write("**ğŸ” ë””ë²„ê¹… ì •ë³´:**")
            
            # í˜ì´ì§€ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
            try:
                test_url = f"https://www.youtube.com/watch?v={video_id}"
                test_response = requests.get(test_url, timeout=10)
                st.write(f"- í˜ì´ì§€ ì ‘ê·¼: âœ… ì„±ê³µ (ìƒíƒœì½”ë“œ: {test_response.status_code})")
                
                # captionTracks íŒ¨í„´ ê²€ìƒ‰
                if '"captionTracks"' in test_response.text:
                    st.write("- captionTracks íŒ¨í„´: âœ… ë°œê²¬ë¨")
                    
                    # ì‹¤ì œ ë§¤ì¹˜ ì‹œë„
                    match = re.search(r'"captionTracks":\s*(\[.*?\])', test_response.text)
                    if match:
                        st.write("- ì •ê·œì‹ ë§¤ì¹˜: âœ… ì„±ê³µ")
                        try:
                            tracks_str = match.group(1).encode('utf-8').decode('unicode_escape')
                            tracks = json.loads(tracks_str)
                            st.write(f"- JSON íŒŒì‹±: âœ… ì„±ê³µ ({len(tracks)}ê°œ íŠ¸ë™)")
                            
                            # ê° íŠ¸ë™ ì •ë³´ í‘œì‹œ
                            for i, track in enumerate(tracks):
                                track_info = f"íŠ¸ë™ {i+1}: "
                                if 'languageCode' in track:
                                    track_info += f"ì–¸ì–´={track['languageCode']}, "
                                if 'kind' in track:
                                    track_info += f"íƒ€ì…={track['kind']}, "
                                else:
                                    track_info += "íƒ€ì…=ìˆ˜ë™, "
                                if 'baseUrl' in track:
                                    track_info += "URL=ìˆìŒ"
                                else:
                                    track_info += "URL=ì—†ìŒ"
                                st.write(f"  - {track_info}")
                                
                        except json.JSONDecodeError as e:
                            st.write(f"- JSON íŒŒì‹±: âŒ ì‹¤íŒ¨ ({e})")
                        except Exception as e:
                            st.write(f"- íŠ¸ë™ ì²˜ë¦¬: âŒ ì‹¤íŒ¨ ({e})")
                    else:
                        st.write("- ì •ê·œì‹ ë§¤ì¹˜: âŒ ì‹¤íŒ¨")
                else:
                    st.write("- captionTracks íŒ¨í„´: âŒ ì—†ìŒ")
                    
            except Exception as e:
                st.write(f"- í˜ì´ì§€ ì ‘ê·¼: âŒ ì‹¤íŒ¨ ({e})")
            
            # timedtext API í…ŒìŠ¤íŠ¸
            try:
                timedtext_url = f"https://www.youtube.com/api/timedtext?type=list&v={video_id}"
                timedtext_response = requests.get(timedtext_url, timeout=10)
                st.write(f"- timedtext API: ìƒíƒœì½”ë“œ {timedtext_response.status_code}")
                if timedtext_response.status_code == 200 and timedtext_response.text.strip():
                    st.write(f"- timedtext ì‘ë‹µ ê¸¸ì´: {len(timedtext_response.text)} ë¬¸ì")
                    try:
                        root = ET.fromstring(timedtext_response.text)
                        tracks = root.findall('.//track')
                        st.write(f"- timedtext íŠ¸ë™ ìˆ˜: {len(tracks)}ê°œ")
                    except ET.ParseError as e:
                        st.write(f"- timedtext XML íŒŒì‹±: âŒ ì‹¤íŒ¨ ({e})")
                else:
                    st.write("- timedtext API: âŒ ë¹ˆ ì‘ë‹µ")
            except Exception as e:
                st.write(f"- timedtext API: âŒ ì‹¤íŒ¨ ({e})")
            
            with st.expander("ğŸ’¡ í•´ê²° ë°©ë²•"):
                st.markdown("""
                - ë¹„ë””ì˜¤ì— ìë§‰ì´ ìˆëŠ”ì§€ í™•ì¸
                - ë¹„ë””ì˜¤ê°€ ê³µê°œ ìƒíƒœì¸ì§€ í™•ì¸
                - ë‹¤ë¥¸ ë¹„ë””ì˜¤ë¡œ ì‹œë„
                - ëª‡ ë¶„ í›„ ë‹¤ì‹œ ì‹œë„
                """)
            return
        
        st.success(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ! ({method})")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ“œ ì›ë³¸ ìë§‰")
            st.text_area("ìë§‰ ë‚´ìš©", transcript_text, height=400)
            st.download_button(
                "ğŸ“¥ ìë§‰ ë‹¤ìš´ë¡œë“œ",
                transcript_text,
                f"transcript_{video_id}.txt",
                mime="text/plain",
                key="download_transcript"
            )
        
        with col2:
            st.markdown("### ğŸ¤– AI ìš”ì•½")
            with st.spinner("ìš”ì•½ ìƒì„± ì¤‘..."):
                summary = summarize_text(transcript_text, gemini_api_key)
            
            st.markdown(summary)
            st.download_button(
                "ğŸ“¥ ìš”ì•½ ë‹¤ìš´ë¡œë“œ",
                summary,
                f"summary_{video_id}.md",
                mime="text/markdown",
                key="download_summary"
            )

if __name__ == "__main__":
    main()
